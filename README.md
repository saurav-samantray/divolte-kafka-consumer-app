# Divolte Kafka Consumer Application
Simple Spring Boot application that can consume click-stream events generated by Divolte Collection and published to Kafka brokers

## Divolte
Divolte Collector is a scalable and performant server for collecting clickstream data in HDFS and on Kafka topics.

## Kafka
Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.

## Clickstream data
All clickstream data generated from client is posted from Divolte.js to Divolte-Collector. The Divolte Collecter has a avro schema (avsc file) mapping based on which it structures the data. However as Kafka dosen't understand schema, the avro schema mapped data is serialized and put into Kafka.

This spring boot app has a kafka listener configured that deserializes the data unto an auto generated Avro Schema.

## Build.

Run maven generate-source to generate the avro schema from the avsc file located at src/main/resources. Make sure that your custom avsc file is also placed in the same location. The schema java file will generated in target\generated-sources . (Auto generated java for default divolte clickstream record is committed to src\main\java\com\divolte\consumer\dto\DefaultEventRecord.java )


## Running dependencies
In order to try out this application you will need to bring up zookeeper, kafka and divolte-collector instances. You can use the docker-compose.yaml file present inside *dependecy* folder and run the command *docker-compose up --build*

## Testing
Once all the docker instances are up you can run the spring boot application which will start listening to the *divolte* kafka topic. Access the below url which is a sample UI application which can generate clickstream data.

http://localhost:8290/

